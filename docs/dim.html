

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>8. Dimension Reduction Algorithms &mdash; Data Mining With Python and R  documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/icon.ico"/>
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="_static/contentui.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/fix_rtd.css" type="text/css" />
  <link rel="stylesheet" href="_static/contentui.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. Regression Algorithm" href="regression.html" />
    <link rel="prev" title="7. Summary of Data Mining Algorithms" href="algsummary.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Data Mining With Python and R
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="preface.html">1. Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="comparison.html">2. Python or R for data analysis?</a></li>
<li class="toctree-l1"><a class="reference internal" href="gettingstarted.html">3. Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="de.html">4. Data Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="dm.html">5. Data Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pre.html">6. Pre-processing procedures</a></li>
<li class="toctree-l1"><a class="reference internal" href="algsummary.html">7. Summary of Data Mining Algorithms</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8. Dimension Reduction Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-dimension-reduction">8.1. What is dimension reduction?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#singular-value-decomposition-svd">8.2. Singular Value Decomposition (SVD)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#principal-component-analysis-pca">8.3. Principal Component Analysis (PCA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#independent-component-analysis-ica">8.4. Independent Component Analysis (ICA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nonnegative-matrix-factorization-nmf">8.5. Nonnegative matrix factorization (NMF)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="regression.html">9. Regression Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">10. Classification ALgorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="reg.html">11. Regularization ALgorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="resample.html">12. Resampling Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpkg.html">13. Developing Your Own R Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="ppkg.html">14. Developing Your Own Python Packages</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Data Mining With Python and R</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>8. Dimension Reduction Algorithms</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/runawayhorse001/DatamingTutorial/blob/master/doc/dim.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <span class="target" id="dim"></span><div class="section" id="dimension-reduction-algorithms">
<span id="index-0"></span><h1>8. Dimension Reduction Algorithms<a class="headerlink" href="#dimension-reduction-algorithms" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-is-dimension-reduction">
<h2>8.1. What is dimension reduction?<a class="headerlink" href="#what-is-dimension-reduction" title="Permalink to this headline">¶</a></h2>
<p>In machine learning and statistics, dimensionality reduction or dimension reduction is the process of reducing the number of random variables under consideration,
via obtaining a set “uncorrelated” principle variables. It can be divided into feature selection and feature extraction. <a class="reference external" href="https://en.wikipedia.org/wiki/Dimensionality_reduction">https://en.wikipedia.org/wiki/Dimensionality_reduction</a></p>
</div>
<div class="section" id="singular-value-decomposition-svd">
<span id="index-1"></span><h2>8.2. Singular Value Decomposition (SVD)<a class="headerlink" href="#singular-value-decomposition-svd" title="Permalink to this headline">¶</a></h2>
<p>At here, I will recall the three types of the SVD method, since some authors confused
the definitions of these SVD method. SVD method is important for the the dimension reduction
algorithms, such as Truncated Singular Value Decomposition (tSVD) can be used to do the dimension
reduction directly, and the Full Rank Singular Value Decomposition (SVD) can be applied to do Principal Component Analysis (PCA), since PCA is a specific case of SVD.</p>
<ol class="arabic simple">
<li><strong>Full Rank Singular Value Decomposition (SVD)</strong></li>
</ol>
<blockquote>
<div><p>Suppose <img class="math" src="_images/math/c8acdce43baa5227707f4ec947fd6c03af51fd1b.png" alt="{\bf X}\in\mathbb{R}^{n\times p}, (p&lt;n)"/>, then</p>
<div class="math">
<p><img src="_images/math/ee2bdc10dbb8b1fcf2cb6c92690cebe7786b7492.png" alt="\underbracket{\bf X}_{n\times p} =\underbracket{\bf U}_{n\times n} \underbracket{\bf\Sigma}_{n\times p} \underbracket{{\bf V}^T}_{p\times p},"/></p>
</div><p>is called a full rank <strong>SVD</strong> of <img class="math" src="_images/math/cc33b8fee6fbb446b2cb4be367ed9ea31372992d.png" alt="{\bf X}"/> and</p>
<ul class="simple">
<li><img class="math" src="_images/math/4d141bf58c99791e2c7fbf8d6e3374be256af1f2.png" alt="\sigma_i"/>– Sigular calues and <img class="math" src="_images/math/cb66e6bfef0185ae1e7b77776f4934ef314c8f44.png" alt="{\bf\Sigma}=diag(\sigma_1,\sigma_2, \cdots, \sigma_p)\in \mathbb{R}^{n\times p}"/></li>
<li><img class="math" src="_images/math/1f72a490ad24f07998d236892ec6d09d90ed8946.png" alt="u_i"/>– left singular vectors, <img class="math" src="_images/math/ea760680b07b1b356dc6afbeb089c8bca1f09108.png" alt="{\bf U}=[u_1,u_2, \cdots, u_n]"/> and  <img class="math" src="_images/math/ce3cd86b3e2256b8d2dce29531ee8b4d9105cefd.png" alt="{\bf U}"/> is unitary.</li>
<li><img class="math" src="_images/math/142881538f656982dcb5aa2fc27ddbc247965b5a.png" alt="v_i"/>– right singular vectors, <img class="math" src="_images/math/d226f9a1719c1b64609c64444029f1b7ad5bb719.png" alt="{\bf V}=[v_1,v_2, \cdots, v_p]"/> and  <img class="math" src="_images/math/70cf09f3b5555d649daf5e2ab69ed9090164df3d.png" alt="{\bf V}"/> is unitary.</li>
</ul>
<blockquote>
<div><div class="figure align-center" id="id1">
<span id="fig-svd"></span><img alt="_images/svd.png" src="_images/svd.png" />
<p class="caption"><span class="caption-text">Singular Value Decomposition</span></p>
</div>
</div></blockquote>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><strong>Reduced Singular Value Decomposition (rSVD)</strong></li>
</ol>
<blockquote>
<div><p>Suppose <img class="math" src="_images/math/765825c17a03cfa8920775d92bff9419cc9f8a88.png" alt="{\bf X}\in\mathbb{R}^{n\times p},(n&lt;p)"/>, then</p>
<div class="math">
<p><img src="_images/math/9884ab6abe2a731bfd6571a3d409f28480dfd238.png" alt="\underbracket{\bf X}_{n\times p} =\underbracket{\bf \hat{U}}_{n\times p} \underbracket{\bf\hat{\Sigma}}_{p\times p} \underbracket{{\bf \hat{V}}^T}_{p\times p},"/></p>
</div><p>is called a Reduced Singular Value Decomposition <strong>rSVD</strong> of <img class="math" src="_images/math/dde91fd8574d9fbf67ac91679710c860a57682e1.png" alt="{\bX}"/> and</p>
<ul class="simple">
<li><img class="math" src="_images/math/4d141bf58c99791e2c7fbf8d6e3374be256af1f2.png" alt="\sigma_i"/>– Sigular calues and <img class="math" src="_images/math/46c3f334186061ef5330f2eb77e4b3fc0a4442d6.png" alt="{\bf\hat{\Sigma}}=diag(\sigma_1,\sigma_2, \cdots, \sigma_p)\in \mathbb{R}^{p\times p}"/></li>
<li><img class="math" src="_images/math/1f72a490ad24f07998d236892ec6d09d90ed8946.png" alt="u_i"/>– left singular vectors, <img class="math" src="_images/math/2e52f9ed4015b0a88639d9fcfc5937ad2d041250.png" alt="{\bf \hat{U}}=[u_1,u_2, \cdots, u_p]"/> is column-orthonormal matrix.</li>
<li><img class="math" src="_images/math/142881538f656982dcb5aa2fc27ddbc247965b5a.png" alt="v_i"/>– right singular vectors, <img class="math" src="_images/math/631192b067b519e9202bc2503dd34f51b1f33183.png" alt="{\bf \hat{V}}=[v_1,v_2, \cdots, v_p]"/> is column-orthonormal matrix.</li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><strong>Truncated Singular Value Decomposition (tSVD)</strong></li>
</ol>
<blockquote>
<div><p>Suppose <img class="math" src="_images/math/d4461c32354b9845872bc56cf4af09ee1a0a6899.png" alt="{\bf X}\in\mathbb{R}^{n\times p},(r&lt;p)"/>, then</p>
<div class="math" id="equation-tsvd">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-tsvd" title="Permalink to this equation">¶</a></span><img src="_images/math/8d63532ca2663acb390f6493f3bdd7d7fe194cfc.png" alt="\underbracket{\bf X}_{n\times p} =\underbracket{\bf \hat{U}}_{n\times r} \underbracket{\bf\hat{\Sigma}}_{r\times r} \underbracket{{\bf \hat{V}}^T}_{r\times p},"/></p>
</div><p>is called a Truncated Singular Value Decomposition <strong>tSVD</strong> of <img class="math" src="_images/math/cc33b8fee6fbb446b2cb4be367ed9ea31372992d.png" alt="{\bf X}"/> and</p>
<ul class="simple">
<li><img class="math" src="_images/math/4d141bf58c99791e2c7fbf8d6e3374be256af1f2.png" alt="\sigma_i"/>– Sigular calues and <img class="math" src="_images/math/807c634fc18bf12afec9c6f253ca4b7f54f5e55b.png" alt="{\bf\hat{\Sigma}}=diag(\sigma_1,\sigma_2, \cdots, \sigma_r)\in \mathbb{R}^{r\times r}"/></li>
<li><img class="math" src="_images/math/1f72a490ad24f07998d236892ec6d09d90ed8946.png" alt="u_i"/>– left singular vectors, <img class="math" src="_images/math/5fbb61bf44bbd87a3ac1e7235dd319d005338b2f.png" alt="{\bf \hat{U}}=[u_1,u_2, \cdots, u_r]"/> is column-orthonormal matrix.</li>
<li><img class="math" src="_images/math/142881538f656982dcb5aa2fc27ddbc247965b5a.png" alt="v_i"/>– right singular vectors, <img class="math" src="_images/math/631192b067b519e9202bc2503dd34f51b1f33183.png" alt="{\bf \hat{V}}=[v_1,v_2, \cdots, v_p]"/> is column-orthonormal matrix.</li>
</ul>
<blockquote>
<div><div class="figure align-center" id="id2">
<span id="fig-tsvd"></span><img alt="_images/tsvd.png" src="_images/tsvd.png" />
<p class="caption"><span class="caption-text">Truncated Singular Value Decomposition</span></p>
</div>
</div></blockquote>
</div></blockquote>
<p>Figure <a class="reference internal" href="#fig-tsvd"><span class="std std-ref">Truncated Singular Value Decomposition</span></a> indictes that the the dimension of <img class="math" src="_images/math/c6337ee1b8ce875e48b7753c0816087c76f75f7b.png" alt="{\bf \hat{U}}"/> is smaller than <img class="math" src="_images/math/cc33b8fee6fbb446b2cb4be367ed9ea31372992d.png" alt="{\bf X}"/>. We can use this property to do the dimension reduction. But, usually, we will use SVD
to compute the Principal Components. We will learn more details in next section.</p>
</div>
<div class="section" id="principal-component-analysis-pca">
<span id="index-2"></span><h2>8.3. Principal Component Analysis (PCA)<a class="headerlink" href="#principal-component-analysis-pca" title="Permalink to this headline">¶</a></h2>
<p>Usually, there are two ways to implement the PCA. Principal Component Analysis (PCA) is a specific case of SVD.</p>
<blockquote>
<div><div class="math" id="equation-test">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-test" title="Permalink to this equation">¶</a></span><img src="_images/math/90b47ed0b38d36620ad073065b9f1848e0f4a64f.png" alt="\underbracket{\bX}_{n\times p} =\hU"/></p>
</div></div></blockquote>
</div>
<div class="section" id="independent-component-analysis-ica">
<span id="index-3"></span><h2>8.4. Independent Component Analysis (ICA)<a class="headerlink" href="#independent-component-analysis-ica" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="nonnegative-matrix-factorization-nmf">
<span id="index-4"></span><h2>8.5. Nonnegative matrix factorization (NMF)<a class="headerlink" href="#nonnegative-matrix-factorization-nmf" title="Permalink to this headline">¶</a></h2>
<p>TO DO……</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="regression.html" class="btn btn-neutral float-right" title="9. Regression Algorithm" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="algsummary.html" class="btn btn-neutral float-left" title="7. Summary of Data Mining Algorithms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Wenqiang Feng and Ming Chen
      <span class="lastupdated">
        Last updated on Apr 27, 2019.
      </span>

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>